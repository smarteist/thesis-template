
\chapter{کارهای پیشین}

در فصل سوم پایان‌نامه، کارهای پیشین انجام‌شده روی مسئله به تفصیل توضیح داده می‌شود.
نمونه‌ای از فصل کارهای پیشین در زیر آمده است.\footnote{
مطالب این فصل نمونه از پایان‌نامه‌ی آقای بهنام حاتمی گرفته شده است.}


\section{مسائل خوشه‌بندی}

مسئله‌ی \bb{خوشه‌بندی}\footnotefa{Clustering} یکی از مهم‌ترین مسائل در زمینه‌ی داده‌کاوی به حساب می‌آید.
در این مسئله، هدف دسته‌بندی تعدادی شیء به‌گونه‌ای است که اشیاء درون یک دسته (خوشه)، نسبت به یکدیگر در برابر دسته‌های دیگر شبیه‌تر باشند (معیارهای متفاوتی برای تشابه تعریف می‌گردد).
این مسئله در حوزه‌های مختلفی از علوم کامپیوتر از جمله داده‌کاوی، جست‌وجوی الگو\footnotefa{Pattern recognition}، پردازش تصویر\footnotefa{Image analysis}، بازیابی اطلاعات\footnotefa{Information retrieval} و رایانش زیستی\footnotefa{Bioinformatics} مورد استفاده قرار می‌گیرد~\cite{han2006}.

تا کنون راه‌حل‌های زیادی برای این مسئله ارائه شده است که از لحاظ معیار تشخیص خوشه‌ها و نحوه‌ی انتخاب یک خوشه، با یک‌دیگر تفاوت بسیاری دارند.
به همین خاطر مسئله‌ی خوشه‌بندی یک مسئله‌ی بهینه‌سازی چندهدفه\footnotefa{Multi-objective} محسوب می‌شود.


همان طور که در مرجع \cite{estivill2002so} ذکر شده است، خوشه در خوشه‌بندی تعریف واحدی ندارد و یکی از دلایل وجود الگوریتم‌های متفاوت، همین تفاوت تعریف‌ها از خوشه است.
بنابراین با توجه به مدلی که برای خوشه‌ها ارائه می‌شود، الگوریتم متفاوتی نیز ارائه می‌گردد.
در ادامه به بررسی تعدادی از معروف‌ترین مدل‌های مطرح می‌پردازیم:

\begin{itemize}

\item
\bb{مدل‌های مرکزگرا}: در این مدل‌ها، هر دسته با یک مرکز نشان داده می‌شود.
از جمله معروف‌ترین روش‌های خوشه‌بندی بر اساس این مدل،  خوشه‌بندی $k$-مرکز، خوشه‌بندی $k$-میانگین\footnotefa{$k$-Means} و خوشه‌بندی $k$-میانه\footnotefa{$k$-Median} است.

\item
\bb{مدل‌های مبتی بر توزیع نقاط}: در این مدل، دسته‌ها با فرض پیروی از یک توزیع احتمالی مشخص می‌شوند.
از جمله الگوریتم‌های معروف ارائه شده در این مدل، الگوریتم بیشینه‌سازی امید ریاضی\footnotefa{Expectation-maximization} است.

\item
\bb{مدل‌های مبتنی بر تراکم نقاط}: در این مدل، خوشه‌ها متناسب با ناحیه‌های متراکم نقاط در مجموعه داده مورد استفاده قرار می‌گیرد.

\item
\bb{مدل‌های مبتنی بر گراف}: در این مدل، هر خوشه به مجموعه از رئوس گفته می‌شود که تمام رئوس آن با یک‌دیگر همسایه باشند.
از جمله الگوریتم‌های معروف این مدل، الگوریتم خوشه‌بندی \lr{HCS}\footnotefa{Highly Connected Subgraphs} است.

\end{itemize}

الگوریتم‌های ارائه شده تنها از نظر نوع مدل با یک‌دیگر متفاوت نیستند.
بلکه، می‌توان آن‌ها را از لحاظ نحوه‌ی تخصیص نقاط بین خوشه‌ها نیز تقسیم‌بندی کرد:

\begin{itemize}

\item
\bb{تخصیص قطعی داده‌ها}: در این نوع خوشه‌بندی هر داده دقیقاً به یک خوشه اختصاص داده می‌شود.

\item
\bb{تخصیص قطعی داده‌ها با داده‌ی پرت}: در این نوع خوشه‌بندی ممکن است بعضی از داده‌ها به هیچ خوشه‌ای اختصاص نیابد، اما بقیه داده‌ها هر کدام دقیقاً به یک خوشه اختصاص می‌یابد.

\item
\bb{تخصیص قطعی داده}: در این نوع خوشه‌بندی هر داده دقیقاً به یک خوشه اختصاص داده می‌شود.

\item
\bb{خوشه‌بندی هم‌پوشان}: در این نوع خوشه‌بندی هر داده می‌تواند به چند خوشه اختصاص داده شود.
در گونه‌ای از این مدل، می‌توان هر نقطه را با احتمالی به هر خوشه اختصاص می‌یابد.
به این گونه از خوشه‌بندی، خوشه‌بندی نرم\footnotefa{Soft clustering} گفته می‌شود.

\item
\bb{خوشه‌بندی سلسه‌مراتبی}: در این نوع خوشه‌ها، داده‌ها به گونه‌ای به خوشه‌ها تخصیص داده می‌شود که دو خوشه یا اشتراک ندارند یا یکی به طور کامل دیگری را می‌پوشاند.
در واقع در بین خوشه‌ها، رابطه‌ی پدر فرزندی برقرار است.

\end{itemize}

در بین دسته‌بندی‌های ذکر شده، تمرکز اصلی این پایان‌نامه بر روی مدل مرکزگرا و خوشه‌بندی قطعی با داده‌های پرت با مدل $k$-مرکز است.
همان‌طور که ذکر شد علاوه بر مسئله‌ی $k$-مرکز که به تفصیل مورد بررسی قرار می‌گیرد، $k$-میانه و $k$-میانگین از جمله معروف‌ترین خوشه‌بندی‌های مدل مرکزگرا هستند.
در خوشه‌بندی $k$-میانه، هدف افراز نقاط به $k$ خوشه است به گونه‌ای که مجموع مربع فاصله‌ی هر نقطه از میانه‌ی نقاط آن خوشه، کمینه گردد.
در خوشه‌بندی $k$-میانگین، هدف افراز نقاط به $k$ خوشه است به گونه‌ای که مجموع فاصله‌ی هر نقطه از میانگین نقاط داخل خوشه (یا مرکز آن خوشه) کمینه گردد.

\section{خوشه‌بندی $k$-مرکز}

\rm{
مسئله‌ی خوشه‌بندی، از‌ جمله مسائل مهم علوم کامپیوتر است که مورد توجه بسیاری از دانشمندان قرار گرفته است.
راه‌حل‌های الگوریتمی بسیار زیادی برای خوشه‌بندی ارائه شده است.
این الگوریتم‌ها را براساس رویکرد‌های مختلفی که به مسئله دارند، خوشه‌های متفاوتی به دست می‌آورند.
در عمل هیچ‌کدام از راه‌حل‌های ارائه شده به طور کلی بر دیگری ارجحیت ندارد و باید راه‌حل مدنظر را متناسب با کاربرد مطرح مورد استفاده قرار داد.
به طور مثال استفاده از الگوریتم‌های مرکزگرا، برای خوشه‌های غیر محدب به خوبی عمل نمی‌کند.
یکی از رویکردهای شناخته‌شده برای مسئله‌ی خوشه‌بندی، مسئله‌ی \bb{$\boldsymbol{k}$-مرکز} است.
در این مسئله هدف، پیدا کردن $k$ نقطه به عنوان مرکز دسته‌ها است به‌طوری‌که شعاع دسته‌ها تا حد ممکن کمینه شود.
در نظریه‌ی گراف، مسئله‌ی $k$-مرکز متریک\footnotefa{Metric} یا مسئله‌ی مکان‌یابی تسهیلات متریک\footnotefa{Metric facility location} یک مسئله‌ی بهینه‌سازی ترکیبیاتی\footnotefa{Combinatorial optimization} است.
}



یکی از رویکردهای شناخته‌شده برای مسئله‌ی خوشه‌بندی، مسئله‌ی \bb{$\boldsymbol{k}$-مرکز} است.
در این مسئله هدف، پیدا کردن $k$ نقطه به عنوان مرکز دسته‌ها است به‌طوری‌که شعاع دسته‌ها تا حد ممکن کمینه شود.
%فرض کنید که $n$ شهر و فاصله‌ی دوبه‌دوی آن‌ها، داده‌شده است.
%می‌خواهیم $k$ انبار در شهرهای مختلف بسازیم به‌طوری‌که حداکثر فاصله‌ی هر شهر از نزدیک‌ترین انبار به خود، کمینه گردد.
%در حالت نظریه‌ی گراف آن، این بدان معناست که مجموعه‌ای شامل $k$ رأس انتخاب کنیم به‌طوری‌که بیش‌ترین فاصله‌ی هر نقطه از نزدیک‌ترین نقطه‌اش داخل مجموعه‌ی $k$ عضوی کمینه گردد.
%توجه نمایید که فاصله‌ی بین رئوس باید در فضای متریک\footnotefa{Metric space} باشند و یا به زبان دیگر، یک گراف کامل داشته باشیم که فاصله‌ها در آن در رابطه‌ی مثلثی\footnotefa{Triangle equation} صدق می‌کنند.
مثالی از مسئله‌ی $2$-مرکز در شکل~\ref{شکل:دومرکز} نشان داده شده است.
در این پژوهش، مسئله‌ی $k$-مرکز با متریک‌های خاص و برای $k$های کوچک مورد بررسی قرار گرفته است و هر کدام از‌
تعریف رسمی مسئله‌ی $k$-مرکز در زیر آمده است:

\begin{figure}[t]
\centerimg{k-center}{8cm}
\vspace{1em}
\caption{نمونه‌ای از ‌مسئله‌ی ۲-مرکز}
\label{شکل:دومرکز}
\end{figure}

\begin{مسئله}
\bb{($k$-مرکز)}  گراف کامل بدون جهت $G = (V, E)$ با تابع فاصله‌ی $d$،
که از نامساوی مثلثی پیروی می‌کند داده ‌شده است.
زیرمجموعه‌ی $S \subseteq V$ با اندازه‌ی $k$ را به‌گونه‌ای انتخاب کنید که عبارت زیر را کمینه کند:
\begin{equation}
\max_{v \in V} \{ \min_{s \in S} d(v, s) \}
\end{equation}
\end{مسئله}

گونه‌های مختلفی از مسئله‌ی $k$-مرکز با محدودیت‌های متفاوت توسط پژوهشگران مورد مطالعه قرار گرفته است.
از جمله‌ی این گونه‌ها، می‌توان به حالتی که در بین داده‌های ورودی، داده‌های پرت وجود دارد، اشاره کرد.
در واقع در این مسئله، قبل از خوشه‌بندی می‌توانیم تعدادی از نقاط ورودی را حذف نموده و سپس به خوشه‌بندی نقاط بپردازیم.
سختی این مسئله از آنجاست که نه تنها باید مسئله‌ی خوشه‌بندی را حل نمود، بلکه در ابتدا باید تصمیم گرفت که کدام یک از داده‌ها را به‌عنوان داده‌ی پرت در نظر گرفت که بهترین جواب در زمان خوشه‌بندی به دست آید.
در واقع اگر تعداد نقاط پرتی که مجاز به حذف است، برابر صفر باشد، مسئله به مسئله‌ی $k$-مرکز تبدیل می‌شود.
نمونه‌ای از مسئله‌ی $2$-مرکز با $7$ داده‌ی پرت را در شکل~\ref{شکل:دومرکزپرت} می‌توانید ببینید.
تعریف دقیق‌تر این مسئله در زیر آمده است:

\begin{problem}
    \textbf{($k$-مرکز با داده‌های پرت)} یک گراف کامل بدون جهت $G = (V, E)$ با تابع فاصله‌ی $d$، که از نامساوی مثلثی پیروی می‌کند داده‌شده است. زیرمجموعه‌ی $Z \subseteq V$ با اندازه‌ی $z$ و مجموعه‌ی $S \subseteq V - Z$ با اندازه‌ی $k$ را انتخاب کنید به‌طوری‌که عبارت زیر را کمینه کند:
    \begin{equation}
        \max_{v \in V - Z} \{ \min_{s \in S} d(v, s) \}
    \end{equation}
\end{problem}

\begin{figure}[t]
\centerimg{outlier}{8cm}
\caption{نمونه‌ای از‌مسئله‌ی ۲-مرکز با داده‌های پرت}
\label{شکل:دومرکزپرت}
\end{figure}

گونه‌ی دیگری از مسئله‌ی $k$-مرکز که در سال‌های اخیر مورد توجه قرار گرفته است، حالت جویبار داده‌ی آن است.
در این‌گونه از مسئله‌ی $k$-مرکز، در ابتدا تمام نقاط در دسترس نیستند، بلکه به‌مرور زمان نقاط در دسترس قرار می‌گیرند.
محدودیت دومی که وجود دارد، محدودیت حافظه است، به‌طوری‌که نمی‌توان تمام نقاط را در حافظه نگه داشت و بعضاً حتی امکان نگه‌داری در حافظه‌ی جانبی نیز وجود ندارد و به‌طور معمول باید مرتبه‌ی حافظه‌ای کم‌تر از مرتبه حافظه‌ی \bb{خطی}\footnotefa{Linear} متناسب با تعداد نقاط استفاده نمود.
از این به بعد به چنین مرتبه‌ای، مرتبه‌ی \bb{زیرخطی}\footnotefa{sublinear} می‌گوییم.
مدلی که ما در این پژوهش بر روی آن تمرکز داریم مدل جویبار داده تک‌گذره\footnotefa{Single pass}~\cite{aggarwal2007data} است.
یعنی تنها یک بار می‌توان از ابتدا تا انتهای داده‌ها را بررسی کرد و پس از عبور از یک داده، اگر آن داده در حافظه ذخیره نشده باشد، دیگر به آن دسترسی وجود ندارد. علاوه بر این، در هر لحظه باید بتوان به پرسمان (برای تمام نقاطی از جویبار داده که تاکنون به آن دسترسی داشته‌ایم) پاسخ داد.

\rm{
یکی از دغدغه‌هایی که در مسائل جویبار داده وجود دارد، عدم امکان دسترسی به تمام نقاط است.
در واقع هم این مشکل وجود دارد که به تمام داده‌های قبلی دسترسی نداریم و هم این مشکل وجود دارد که هیچ اطلاعی از داده‌های آتی نداریم.
در نتیجه یکی از تبعات این‌گونه از مسئله‌ی $k$-مرکز، امکان انتخاب نقطه‌ای به عنوان مرکز برای یک دسته است به‌طوری‌که در بین نقاط ورودی نیست.
زیرا از نقاطی که تاکنون آمده‌اند به طور کامل اطلاع نداریم.
\begin{تعریف}[متریک $L_p$]
به ازای دو نقطه‌ی $d$-بعدی $s(s_1, \cdots, s_d)$ و $q(q_1, \cdots, q_d)$، فاصله‌ی $p$ و $q$ در متریک $L_p$ برابر است با:
$$d(p, q) = \sqrt[p]{\sum_{i=1}^{d} (s_i - q_i) ^ p}$$
\end{تعریف}
این‌گونه از مسئله‌ی $k$-مرکز، معمولاً تنها برای $L_p$-متریک مطرح می‌شود یا حالتی که ما مجموعه‌ای از تمام نقاط فضا به انضمام فاصله‌هایشان را داشته باشیم.
زیرا مرکز دسته‌ها ممکن است در هر نقطه از فضا قرار بگیرد و ما نیاز داریم که فاصله‌ی آن را از تمام نقاط بدانیم.
نمونه‌ای از مسئله‌ی $2$-مرکز در حالت پیوسته، در شکل \ref{شکل:دومرکزپیوسته} نشان داده شده است.
تعریف دقیق گونه‌ی جویبار داده‌ی مسئله‌ی $k$‌-مرکز، در زیر آمده است:

\begin{figure}[t]

\caption{نمونه‌ای از ‌مسئله‌ی ۲-مرکز در حالت پیوسته}
\label{شکل:دومرکزپیوسته}
\end{figure}
}

\begin{problem}
    \textbf{($k$-مرکز در حالت جویبار داده)} مجموعه‌ای از نقاط در فضای $d$-بعدی به مرور زمان داده می‌شود. در هر لحظه از زمان، به ازای مجموعه‌ی $U$ از نقاطی که تا کنون وارد شده‌اند، زیرمجموعه‌ی $S \subseteq U$ با اندازه‌ی $k$ را انتخاب کنید به‌طوری‌که عبارت زیر کمینه شود:
    \begin{equation}
        \max_{u \in U} \{ \min_{s \in S} d(u, s) \}
    \end{equation}
\end{problem}

از آنجایی که گونه‌ی جویبار داده و داده پرت مسئله‌ی $k$-مرکز به علت به‌روز بودن مبحث داده‌های حجیم\footnotefa{Big data}، به تازگی مورد توجه قرار گرفته است.
در این تحقیق سعی شده است که تمرکز بر روی این‌گونه‌ی خاص از مسئله باشد.
همچنین در این پژوهش سعی می‌شود گونه‌های مسئله را برای انواع متریک‌ها و برای $k$های کوچک نیز مورد بررسی قرار داد.

\section{مدل جویبار داده}

همان‌طور که ذکر شد مسئله‌ی $k$-مرکز در حالت داده‌های پرت و جویبار داده، گونه‌های تعمیم‌یافته از مسئله‌ی $k$-مرکز هستند و در حالت‌های خاص به مسئله‌ی $k$-مرکز کاهش پیدا می‌کنند.
مسئله‌ی $k$-مرکز در حوزه‌ی مسائل ان‌پی-سخت\footnotefa{NP-hard} قرار می‌گیرد و با فرض $P \neq NP$ الگوریتم دقیق با زمان چندجمله‌ای برای آن وجود ندارد \cite{michael1979computers}.
بنابراین برای حل کارای\footnotefa{Efficient} این مسائل از الگوریتم‌های تقریبی\footnotefa{Approximation algorithm} استفاده می‌شود.

برای مسئله‌ی $k$-مرکز، دو الگوریتم تقریبی معروف وجود دارد.
در الگوریتم اول، که به روش حریصانه\footnotefa{Greedy} عمل می‌کند، در هر مرحله بهترین مرکز ممکن را انتخاب می‌کند به طوری تا حد ممکن از مراکز قبلی دور باشد~\cite{megiddo1984complexity}.
این الگوریتم، الگوریتم تقریبی با ضریب تقریب 2 ارائه می‌دهد.
در الگوریتم دوم، با استفاده از مسئله‌ی مجموعه‌ی غالب کمینه\footnotefa{Dominating set}، الگوریتمی با ضریب تقریب ۲ ارائه می‌گردد \cite{vazirani2013approximation}.
همچنین ثابت شده است، که بهتر از این ضریب تقریب، الگوریتمی نمی‌توان ارائه داد مگر آن‌که $P = NP$ باشد.

برای مسئله‌ی $k$-مرکز در حالت جویبار داده برای ابعاد بالا، بهترین الگوریتم موجود ضریب تقریب $2 + \epsilon$ دارد \cite{mccutchen2008streaming, guha2009tight, ahn2014computing} و ثابت می‌شود الگوریتمی با ضریب تقریب بهتر از $2$ نمی‌توان ارائه داد. برای مسئله‌ی $k$-مرکز با داده‌ی پرت در حالت جویبار داده نیز، بهترین الگوریتم ارائه شده، الگوریتمی با ضریب تقریب $4 + \epsilon$ است که با کران پایین $3$ هنوز اختلاف قابل توجهی دارد \cite{charikar2001algorithms}.

برای $k$های کوچک به خصوص، $k =1, 2$، الگوریتم‌های بهتری ارائه شده است. بهترین الگوریتم ارائه شده برای مسئله‌ی $1$-مرکز در حالت جویبار داده برای ابعاد بالا، دارای ضریب تقریب $1.22$ است و کران پایین $\frac{1 + \sqrt{2}}{2}$ نیز برای این مسئله اثبات شده است \cite{agarwal2010streaming, chan2014streaming}. برای مسئله $2$-مرکز در حالت جویبار داده برای ابعاد بالا، اخیرا راه‌حلی با ضریب تقریب $1.8 + \epsilon$ ارائه شده است \cite{kim2014improved}. برای مسئله‌ی $1$-مرکز با داده‌ی پرت، تنها الگوریتم موجود، الگوریتمی با ضریب تقریب $1.73$ است \cite{zarrabi2009streaming}.

\section{تقریب‌پذیری}

یکی از راه‌کارهایی که برای کارآمد کردن راه‌حل ارائه شده برای یک مسئله وجود دارد، استفاده از الگوریتم‌های تقریبی برای حل آن مسئله است.
یکی از عمده‌ترین دغدغه‌های مطرح در الگوریتم‌های تقریبی کاهش ضریب تقریب است.
در بعضی از موارد حتی امکان ارائه‌ی الگوریتم تقریبی با ضریبی ثابت نیز وجود ندارد.
به طور مثال، الگوریتم تقریبی با ضریب تقریب کم‌تر از $2$، برای مسئله‌ی $k$-مرکز وجود ندارد مگر این‌که $P = NP$ باشد.
برای مسائل مختلف، معمولاً می‌توان کران پایینی برای میزان تقریب‌پذیری آن‌ها ارائه داد.
در واقع برای برخی مسائل ان‌پی-سخت، علاوه بر این که الگوریتم کارآمدی وجود ندارد، بعضاً الگوریتم تقریبی با ضریبی تقریب کم و نزدیک به یک نیز وجود ندارد.
در جدول \ref{جدول:تقریب‌پذیری}  میزان تقریب‌پذیری مسائل مختلفی که در این پایان‌نامه مورد استفاده قرار می‌گیرد را می‌بینید.




\begin{figure}[t]
    \centering
    \caption{نمونه‌هایی از کران پایین تقریب‌پذیری مسائل خوشه‌بندی}

    \begin{tabular}{|c|c|}
        \hline
        \textbf{مسئله} & \textbf{کران پایین تقریب‌پذیری} \\
        \hline
        $k$-مرکز & $2$ \cite{vazirani2013approximation} \\
        $k$-مرکز در فضای اقلیدسی & $1.822$ \cite{bern1996approximation} \\
        $1$-مرکز در حالت جویبار داده & $\frac{1 + \sqrt{2}}{2}$ \cite{agarwal2010streaming} \\
        $k$-مرکز با نقاط پرت و نقاط اجباری & $3$ \cite{charikar2001algorithms} \\
        \hline
    \end{tabular}

    \label{جدول:تقریب‌پذیری}
\end{figure}
